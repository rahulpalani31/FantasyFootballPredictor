import requests
from bs4 import BeautifulSoup
import pandas as pd


import requests
from bs4 import BeautifulSoup
import pandas as pd

def scrape_nfl_player_stats(url):
    response = requests.get(url)

    # Check if the request is successful
    if response.status_code == 200:
        # Parse HTML content with Beautiful Soup 
        soup = BeautifulSoup(response.text, 'html.parser')

        # Locate the data table with its ID (for rushing stats)
        table = soup.find('table', {'id': 'rushing'})

        if not table:
            print(f"Table with ID 'rushing' not found.")
            return None

        # Extract column headers from <thead>
        headers = [th.text for th in table.find('thead').find_all('th')]

        # Extract row data from <tbody>
        rows = table.find('tbody').find_all('tr')

        # Prepare a list for row data
        data = []
        for row in rows:
            row_data = [td.text.strip() for td in row.find_all(['th', 'td'])]

            # Check if the row data length matches the headers length
            if len(row_data) == len(headers):
                data.append(row_data)
            else:
                # Print a warning for rows that don't match the number of headers
                print(f"Skipping row with {len(row_data)} columns (expected {len(headers)}): {row_data}")

        # Convert the data into a pandas DataFrame
        df = pd.DataFrame(data, columns=headers)

        print("Data and stats from Pro Football Reference (https://www.pro-football-reference.com/years/2024/rushing.htm)")

        return df

    else:
        # Print error message if the request fails
        print(f"Failed to retrieve the webpage. Status code: {response.status_code}")
        return None


df = scrape_nfl_player_stats("https://www.pro-football-reference.com/years/2024/rushing.htm#rushing")
print(df)
